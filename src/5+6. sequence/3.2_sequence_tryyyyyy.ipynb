{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21586,"status":"ok","timestamp":1698045008977,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"},"user_tz":-540},"id":"TB6s7mmS76cg","outputId":"e7ace7dd-a797-4160-f2e5-84ca6ba5e499"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n","Collecting accelerate>=0.20.3 (from transformers)\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: safetensors, dill, multiprocess, huggingface-hub, tokenizers, accelerate, transformers, datasets\n","Successfully installed accelerate-0.23.0 datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install transformers torch datasets transformers[torch]\n","\n","from google.colab import drive\n","import pandas as pd\n","from datasets import Dataset, DatasetDict, load_from_disk\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, EvalPrediction\n","import torch\n","import json\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43799,"status":"ok","timestamp":1698045052772,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"},"user_tz":-540},"id":"YIbBkS9V77X8","outputId":"275f3688-2e36-429c-f330-5552f41226b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Using cuda device...\n"]},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 163274\n","    })\n","    val: Dataset({\n","        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 72567\n","    })\n","    test: Dataset({\n","        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 54425\n","    })\n","})"]},"metadata":{},"execution_count":2}],"source":["drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/'\n","model_ckpt = 'beomi/KcELECTRA-base-v2022'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # CPU or GPU\n","print(f'Using {device} device...')\n","\n","ds = load_from_disk(file_path+'sequence_dataset')\n","ds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698045052773,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"},"user_tz":-540},"id":"WF9NN_X_PqqQ","outputId":"b636e8d9-6513-45ca-d82c-a9f800804614"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': [1.0, 1.0],\n"," 'input_ids': [2,\n","  8019,\n","  12116,\n","  4235,\n","  4162,\n","  4009,\n","  8141,\n","  2207,\n","  4142,\n","  4180,\n","  2710,\n","  4138,\n","  4217,\n","  22425,\n","  17,\n","  8445,\n","  8019,\n","  1381,\n","  4143,\n","  14071,\n","  14612,\n","  17718,\n","  8767,\n","  3,\n","  2,\n","  11536,\n","  4535,\n","  4019,\n","  609,\n","  10664,\n","  19001,\n","  4063,\n","  7992,\n","  8227,\n","  29092,\n","  8083,\n","  1,\n","  17601,\n","  4180,\n","  16624,\n","  4029,\n","  14194,\n","  4020,\n","  3,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'token_type_ids': [0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'attention_mask': [1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"metadata":{},"execution_count":3}],"source":["ds['train'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3302,"status":"ok","timestamp":1698045125184,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"},"user_tz":-540},"id":"GN0IG5XuMoR8","outputId":"956e5b29-f701-4121-8b17-fe1116727232"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_ckpt, sep_token = '[SEP]', cls_token = '[CLS]')\n","model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n","                                                           problem_type = 'multi_label_classification',\n","                                                           num_labels = 2)\n","\n","model_name = file_path + f\"{model_ckpt}-binary-intent\"\n","# 128은 메모리 부족\n","batch_size = 64\n","logging_steps = len(ds['train']) // batch_size\n","\n","training_args = TrainingArguments(\n","    output_dir = model_name,\n","    logging_dir = model_name + '/logs',\n","    num_train_epochs = 5,\n","    per_device_train_batch_size = batch_size,\n","    per_device_eval_batch_size = batch_size,\n","    logging_steps = logging_steps,\n","    save_steps = 50,\n","    save_total_limit = 2,\n","    save_strategy = 'epoch',\n","    evaluation_strategy = 'epoch',\n","    load_best_model_at_end = True)\n","\n","\n","def multi_label_metrics(predictions, labels, threshold=0.5):\n","    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    # next, use threshold to turn them into integer predictions\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    # finally, compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'weighted')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # return as dictionary\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions,\n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds,\n","        labels=p.label_ids)\n","    return result\n","\n","\n","\n","# def compute_metrics(pred):\n","#     labels = pred.label_ids\n","#     preds = pred.predictions # pred.predictions.argmax(-1)\n","#     f1 = f1_score(labels, preds, average=\"weighted\")\n","#     acc = accuracy_score(labels, preds)\n","#     return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","source":["class MyTrainer(Trainer):\n","    def __init__(self, loss_type, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_type= loss_type\n","\n","    def compute_loss(self, logits, labels):\n","        if self.loss_type == \"ce\":\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n","        elif self.loss_type == \"focal\":\n","            loss_fct = FocalLoss(gamma=self.args.focal_gamma, reduction=\"mean\")\n","            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n","        elif self.loss_type == \"dice\":\n","            loss_fct = DiceLoss(with_logits=True, smooth=self.args.dice_smooth, ohem_ratio=self.args.dice_ohem,\n","                                alpha=self.args.dice_alpha, square_denominator=self.args.dice_square,\n","                                index_label_position=True, reduction=\"mean\")\n","            loss = loss_fct(logits.view(-1, self.num_classes), labels)\n","        else:\n","            raise ValueError\n","        return loss\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xy1MGyMvXie6","executionInfo":{"status":"ok","timestamp":1698045125184,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"3badb266-45e0-406c-eb93-ba57992e473f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["transformers.models.electra.modeling_electra.ElectraForSequenceClassification"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":271},"id":"rDpCpZLMMqgC","executionInfo":{"status":"ok","timestamp":1697707720432,"user_tz":-540,"elapsed":10589727,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"30f00552-44e4-4d1d-ef9e-e09b53dbd8c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12760' max='12760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12760/12760 2:56:25, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.496200</td>\n","      <td>0.407353</td>\n","      <td>0.836984</td>\n","      <td>0.806263</td>\n","      <td>0.676024</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.360700</td>\n","      <td>0.379953</td>\n","      <td>0.853652</td>\n","      <td>0.824420</td>\n","      <td>0.706464</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.274600</td>\n","      <td>0.384855</td>\n","      <td>0.860549</td>\n","      <td>0.833858</td>\n","      <td>0.715739</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.196200</td>\n","      <td>0.421410</td>\n","      <td>0.864897</td>\n","      <td>0.842496</td>\n","      <td>0.728210</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.142000</td>\n","      <td>0.472450</td>\n","      <td>0.865896</td>\n","      <td>0.840705</td>\n","      <td>0.727424</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer = Trainer(model=model, args=training_args,\n","                  compute_metrics=compute_metrics,\n","                  train_dataset=ds['train'],\n","                  eval_dataset=ds['val'],\n","                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n","                  tokenizer=tokenizer)\n","trainer.train();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liinvoutMs1h","colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"status":"ok","timestamp":1697708001432,"user_tz":-540,"elapsed":281006,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"c306149c-7675-4312-8810-c99e0762abc2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1134' max='1134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1134/1134 04:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.3799530267715454,\n"," 'eval_f1': 0.8536516875824545,\n"," 'eval_roc_auc': 0.8244198021366761,\n"," 'eval_accuracy': 0.7064643708572768,\n"," 'eval_runtime': 281.2052,\n"," 'eval_samples_per_second': 258.057,\n"," 'eval_steps_per_second': 4.033,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":6}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNCBYeuKMucI","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1697708214284,"user_tz":-540,"elapsed":212859,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"bc66f569-4e4e-465b-9a0b-5c4d6bdc88a8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'test_loss': 0.38105708360671997,\n"," 'test_f1': 0.8527028210739352,\n"," 'test_roc_auc': 0.8245716583985656,\n"," 'test_accuracy': 0.706550298576022,\n"," 'test_runtime': 213.0644,\n"," 'test_samples_per_second': 255.439,\n"," 'test_steps_per_second': 3.994}"]},"metadata":{},"execution_count":7}],"source":["pred_output = trainer.predict(ds['test'])\n","pred_output.metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTtR10o1MwSP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697708214284,"user_tz":-540,"elapsed":8,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"7aac942c-c7a1-4ae2-b2d8-789658485778"},"outputs":[{"output_type":"stream","name":"stdout","text":["(54425, 2) (54425, 2)\n"]}],"source":["print(pred_output.predictions.shape, pred_output.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ArAlSCvMxyn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697708214284,"user_tz":-540,"elapsed":6,"user":{"displayName":"ᄆᄆ","userId":"06450950622721029831"}},"outputId":"888cc4a6-a8fa-4c96-bf2e-cc52cd3eda95"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[-2.159942  ,  4.027989  ],\n","       [-2.9438853 , -1.3919188 ],\n","       [ 2.5999746 ,  3.375455  ],\n","       ...,\n","       [ 3.524044  , -3.484709  ],\n","       [ 3.943894  ,  1.8889935 ],\n","       [-0.24782501,  3.578032  ]], dtype=float32), label_ids=array([[1., 1.],\n","       [0., 0.],\n","       [1., 1.],\n","       ...,\n","       [1., 0.],\n","       [1., 0.],\n","       [0., 1.]], dtype=float32), metrics={'test_loss': 0.38105708360671997, 'test_f1': 0.8527028210739352, 'test_roc_auc': 0.8245716583985656, 'test_accuracy': 0.706550298576022, 'test_runtime': 213.0644, 'test_samples_per_second': 255.439, 'test_steps_per_second': 3.994})"]},"metadata":{},"execution_count":9}],"source":["pred_output\n","\n","# predictions 기대값 => predictions=array([[[0.xxx, 0.xxx], [0.xxx, 0.xxx]],\n","#                       [[0.xxx, 0.xxx], [0.xxx, 0.xxx]],\n","#                       [[0.xxx, 0.xxx], [0.xxx, 0.xxx]]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKbW1LZrMzNr"},"outputs":[],"source":["trainer.save_model(file_path+\"epc10_weighted_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSYFpDBQ4oAa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdxkO5uQ8MCO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7U8BP1uDRkS"},"outputs":[],"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyP3yrZhKCNSHOR3s6DDLkhw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}